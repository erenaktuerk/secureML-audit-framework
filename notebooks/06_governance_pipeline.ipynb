{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b12bfe5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# ⚙️ 06 – Governance Pipeline: Risk & Compliance for ML\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook outlines a simplified, modular AI governance process for credit risk ML models.\\n\",\n",
    "    \"It includes model metadata logging, risk classification, bias detection, explainability and basic audit traceability.\\n\",\n",
    "    \"\\n\",\n",
    "    \"These principles support regulatory compliance and internal accountability (e.g. under EU AI Act, BaFin, or ISO 42001).\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Imports\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"from src.data_loader import load_and_preprocess_data\\n\",\n",
    "    \"from src.model_trainer import train_model\\n\",\n",
    "    \"from src.risk_assessment import classify_model_risk, detect_bias\\n\",\n",
    "    \"from src.governance import log_model_metadata, generate_audit_entry\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load and train\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = load_and_preprocess_data()\\n\",\n",
    "    \"model = train_model(X_train, y_train)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 1. Log Model Metadata (Traceability)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Log key metadata for governance report\\n\",\n",
    "    \"log_model_metadata(model_name=\\\"RandomForestClassifier\\\",\\n\",\n",
    "    \"                   version=\\\"1.0\\\",\\n\",\n",
    "    \"                   data_source=\\\"German Credit Risk\\\",\\n\",\n",
    "    \"                   owner=\\\"ML Security Analyst\\\",\\n\",\n",
    "    \"                   purpose=\\\"Credit risk scoring\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2. Classify Model Risk (e.g. per EU AI Act)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"risk_level = classify_model_risk(purpose=\\\"credit_scoring\\\", sensitive_features=[\\\"Sex\\\", \\\"Age\\\"])\\n\",\n",
    "    \"print(\\\"Risk classification:\\\", risk_level)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 3. Fairness & Bias Detection (e.g. demographic parity)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"bias_report = detect_bias(X_test, y_test, sensitive_feature=\\\"Sex\\\", model=model)\\n\",\n",
    "    \"bias_report\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 4. Create audit entry\\n\",\n",
    "    \"Generate an auditable JSON log that can be stored in GRC tools.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"generate_audit_entry(model_name=\\\"RandomForestClassifier\\\", risk_level=risk_level, bias=bias_report)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Summary\\n\",\n",
    "    \"\\n\",\n",
    "    \"- Logged metadata for traceability\\n\",\n",
    "    \"- Classified model risk based on usage & sensitivity\\n\",\n",
    "    \"- Detected potential bias based on demographic group\\n\",\n",
    "    \"- Generated audit entry for review/compliance\\n\",\n",
    "    \"\\n\",\n",
    "    \"This pipeline demonstrates a governance layer on top of any AI system – especially valuable in finance and regulated industries.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.10\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
