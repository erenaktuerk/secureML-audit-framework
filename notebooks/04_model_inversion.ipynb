{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e871bf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# 04 – Model Inversion Attack Simulation\\n\",\n",
    "    \"\\n\",\n",
    "    \"In this notebook, we simulate a basic model inversion attack – a technique where attackers attempt to reconstruct sensitive training data by exploiting the predictions of a trained model.\\n\",\n",
    "    \"\\n\",\n",
    "    \"This is particularly relevant in finance and healthcare, where reconstructed features may reveal private or regulatory-relevant attributes.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Imports\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"from src.data_loader import load_and_preprocess_data\\n\",\n",
    "    \"from src.model_trainer import train_model\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"sns.set(style=\\\"whitegrid\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load data and train model\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = load_and_preprocess_data()\\n\",\n",
    "    \"model = train_model(X_train, y_train)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Inversion Goal\\n\",\n",
    "    \"Let's assume an attacker has access to the model and wants to infer sensitive input patterns (e.g. approximate credit amounts of individuals who received credit).\\n\",\n",
    "    \"\\n\",\n",
    "    \"We simulate this by:\\n\",\n",
    "    \"- Fixing all input features except Credit amount\\n\",\n",
    "    \"- Generating inputs with varied Credit amount\\n\",\n",
    "    \"- Observing model outputs to infer thresholds\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Choose one real sample from test set\\n\",\n",
    "    \"base_sample = X_test.iloc[0].copy()\\n\",\n",
    "    \"base_sample_df = pd.DataFrame([base_sample]*50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Modify 'Credit amount' over a range\\n\",\n",
    "    \"base_sample_df[\\\"Credit amount\\\"] = np.linspace(500, 20000, 50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Predict outputs\\n\",\n",
    "    \"probs = model.predict_proba(base_sample_df)[:, 1]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot predictions vs. manipulated feature\\n\",\n",
    "    \"plt.figure(figsize=(8, 4))\\n\",\n",
    "    \"plt.plot(base_sample_df[\\\"Credit amount\\\"], probs)\\n\",\n",
    "    \"plt.xlabel(\\\"Credit amount\\\")\\n\",\n",
    "    \"plt.ylabel(\\\"Predicted Default Probability\\\")\\n\",\n",
    "    \"plt.title(\\\"Model Inversion – Reconstructing Credit Risk Pattern\\\")\\n\",\n",
    "    \"plt.grid(True)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Conclusion\\n\",\n",
    "    \"\\n\",\n",
    "    \"This example demonstrates how prediction APIs can be probed to infer sensitive input-output relationships.\\n\",\n",
    "    \"Model inversion is a known attack vector – especially dangerous in open APIs and unmonitored environments.\\n\",\n",
    "    \"\\n\",\n",
    "    \"Mitigation strategies include output randomization, confidence clipping, or limiting access to probability scores.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.10\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
