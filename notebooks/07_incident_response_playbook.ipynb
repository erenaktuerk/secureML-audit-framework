{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9536fcbf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# 07 ‚Äì AI Security Incident Response Playbook\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook outlines how a security analyst might handle a simulated AI-related incident involving adversarial behavior or model leakage.\\n\",\n",
    "    \"\\n\",\n",
    "    \"It includes classification of the incident, documentation, risk level determination, and response actions based on internal guidelines or AI regulations.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Imports\\n\",\n",
    "    \"from src.risk_assessment import classify_incident\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"from datetime import datetime\\n\",\n",
    "    \"import os\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Simulate a security incident: Model Inversion Detected\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Incident example\\n\",\n",
    "    \"incident = {\\n\",\n",
    "    \"    \\\"id\\\": \\\"INC2025-001\\\",\\n\",\n",
    "    \"    \\\"type\\\": \\\"model_inversion\\\",\\n\",\n",
    "    \"    \\\"severity\\\": \\\"high\\\",\\n\",\n",
    "    \"    \\\"detected_at\\\": datetime.utcnow().isoformat(),\\n\",\n",
    "    \"    \\\"affected_model\\\": \\\"RandomForestClassifier\\\",\\n\",\n",
    "    \"    \\\"exposure_vector\\\": \\\"Public API access\\\",\\n\",\n",
    "    \"    \\\"evidence\\\": \\\"Output probabilities vary systematically with Credit Amount\\\"\\n\",\n",
    "    \"}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### üõ†Ô∏è Step 1 ‚Äì Classify Incident Risk\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"risk_level = classify_incident(attack_type=incident[\\\"type\\\"], severity=incident[\\\"severity\\\"])\\n\",\n",
    "    \"incident[\\\"risk_level\\\"] = risk_level\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Step 2 ‚Äì Document and Save Report\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"os.makedirs(\\\"reports\\\", exist_ok=True)\\n\",\n",
    "    \"with open(\\\"reports/incident_response.json\\\", \\\"w\\\") as f:\\n\",\n",
    "    \"    json.dump(incident, f, indent=4)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Incident response documented.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Step 3 ‚Äì Recommended Actions\\n\",\n",
    "    \"- Disable external access to model predictions (API lockdown)\\n\",\n",
    "    \"- Rotate model version / retrain with stronger defense\\n\",\n",
    "    \"- Apply differential privacy or output clipping\\n\",\n",
    "    \"- Update internal monitoring rules\\n\",\n",
    "    \"- Notify compliance team if personal data exposure possible\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Summary\\n\",\n",
    "    \"This simulated AI incident shows how organizations can react to attacks like model inversion with:\\n\",\n",
    "    \"- Risk classification\\n\",\n",
    "    \"- Rapid response\\n\",\n",
    "    \"- Documentation & audit trail\\n\",\n",
    "    \"- Governance-aligned remediation steps\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.10\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
